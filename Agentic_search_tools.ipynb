{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPMfWv1HXR4z3qAzkEMlDEa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1shkumar/AI-Agents/blob/main/Agentic_search_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JXPn9P34tVr",
        "outputId": "47f87c5b-d73e-48c3-b541-eab503215ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "#code contributed by-Vansh Kumar\n",
        "#github.com/1shkumar\n",
        "#vanshkr22@gmail.com\n",
        "#vansh.kumar.ug21@nsut.ac.in\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 pygments\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRQA6C6szLc8",
        "outputId": "760d6177-9931-45b6-d39b-2904ed29ae3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from pygments import highlight, lexers, formatters\n",
        "import re\n"
      ],
      "metadata": {
        "id": "sy9AoP0HzWPN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EDENAI_API_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiNmM3OWJhOGYtYjNiOC00OTkyLWJkNjItYTA1YzA1Zjk2Zjg2IiwidHlwZSI6ImFwaV90b2tlbiJ9.mvKiWHbwtfbtuhvzJ-sYp5xhnJGBE3H_L2ehQTyaCig'\n"
      ],
      "metadata": {
        "id": "pHx9dDGCzeJF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this function is incomplete\n",
        "def search(query, max_results=6):\n",
        "    url = \"https://api.edenai.run/v1/pretrained/nlp/text_search\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {EDENAI_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"text\": query,\n",
        "        \"num_results\": max_results,\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"results\"]\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}\")\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "x2jvnuTAz1pE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_weather_info(url):\n",
        "    if not url:\n",
        "        return \"Weather information could not be found.\"\n",
        "\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        return \"Failed to retrieve the webpage.\"\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    return soup"
      ],
      "metadata": {
        "id": "918_iElzz5R3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city = \"San Francisco\"\n",
        "query = f\"what is the current weather in {city}? Should I travel there today? weather.com\"\n",
        "\n",
        "\n",
        "search_results = search(query, max_results=6)\n",
        "\n",
        "\n",
        "url = search_results[0][\"url\"] if search_results else \"\"\n",
        "\n",
        "soup = scrape_weather_info(url)\n",
        "\n",
        "\n",
        "if isinstance(soup, BeautifulSoup):\n",
        "\n",
        "    print(f\"Website: {url}\\n\\n\")\n",
        "    print(str(soup.body)[:500])\n",
        "\n",
        "\n",
        "    weather_data = []\n",
        "    for tag in soup.find_all(['h1', 'h2', 'h3', 'p']):\n",
        "        text = tag.get_text(\" \", strip=True)\n",
        "        weather_data.append(text)\n",
        "\n",
        "    weather_data = \"\\n\".join(weather_data)\n",
        "    weather_data = re.sub(r'\\s+', ' ', weather_data)\n",
        "\n",
        "    print(f\"Website: {url}\\n\\n\")\n",
        "    print(weather_data)\n",
        "else:\n",
        "    print(\"Failed to parse the weather information.\")\n",
        "\n",
        "query_gpu = \"What is in Nvidia's new Blackwell GPU?\"\n",
        "\n",
        "\n",
        "result = search(query_gpu, max_results=1)\n",
        "\n",
        "\n",
        "if result:\n",
        "    data = result[0][\"content\"]\n",
        "    print(data)\n",
        "\n",
        "    try:\n",
        "        parsed_json = json.loads(data.replace(\"'\", '\"'))\n",
        "        formatted_json = json.dumps(parsed_json, indent=4)\n",
        "        colorful_json = highlight(formatted_json, lexers.JsonLexer(), formatters.TerminalFormatter())\n",
        "        print(colorful_json)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error parsing JSON data\")\n",
        "else:\n",
        "    print(\"No results found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8LRTrYh0Euu",
        "outputId": "dcca890e-dbf6-4f2d-8bac-a094794a6a3e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 403\n",
            "Failed to parse the weather information.\n",
            "Error: 403\n",
            "No results found.\n"
          ]
        }
      ]
    }
  ]
}